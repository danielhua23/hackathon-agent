# LLM model
api_key: ""
model_id: "Kimi-K2-Instruct"
temperature: 1.0

# TritonBench
statis_path: "/hackathon-agent/src/dataloaders/TB_eval/data/TritonBench_G_comp_alpac_v1_hackathon.json"
py_folder: "/hackathon-agent/src/dataloaders/TB_eval/data/TritonBench_G_v1_hackathon"
instruction_path: "/hackathon-agent/src/dataloaders/TB_eval/data/TritonBench_G_comp_alpac_v1_hackathon.json"
corpus_path: "/hackathon-agent/src/dataloaders/TB_eval/data/train_crawl.json"
golden_metrics: "/hackathon-agent/src/dataloaders/TB_eval/data/performance_metrics/golden_metrics_hackathon"
perf_G_path: "/hackathon-agent/src/dataloaders/TB_eval/data/performance_metrics"
perf_ref_folder: null
py_interpreter: "python"

# configs for resuming optimization process
# result_path: null
# mem_file: null
# start_iter: 0

# target_kernels: ["flash_decode2_phi.py", 'l2_norm_triton1.py', "int4_matmul.py", "sin_kernel.py", "triton_matmul.py", "l2_norm_bwd.py", "matrix_transpose.py", "embedding_triton_kernel.py", "rotary_transform.py", "matrix_vector_multip.py"]
# you can specify which kernels you want to generate by setting target_kernels. null means all 10 kernels for hackathon.
target_kernels: null

# the path where results will be stored
output_path: "/workspace/reflexion_oneshot_tritonbench.json"
max_iteration: 5
# set multi_thread to false if you want to debug the process
multi_thread: true
